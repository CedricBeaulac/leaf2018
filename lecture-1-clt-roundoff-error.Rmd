---
title: "STA261 Summer 2018 Lecture 1:" 
subtitle: "Central Limit Theorem for Round-off Error"
author: "Alex Stringer"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup-noshow, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r setup-show,include=TRUE}
# Load the tidyverse packages
suppressMessages({
  suppressWarnings({
    library(tidyverse)
  })
})
```

In class, we discussed the Central Limit Theorem, regarding the distribution of sums of independent random variables with zero mean and finite variance. Here we provide a computational example to illustrate this concept.

We expand on Question 12 from Chapter 5 of Rice, page 189. Suppose we are adding together a bunch of numbers $x_{i}$, each of which are stored to many decimal places. We want the result of our adding to be an integer, which means we have to round to zero decimal places. Do we round each number and then sum them, or do we sum them and then round the result? Intuitively we might think that there would be less error in rounding once than rounding many times, but you could also argue that since rounding down and rounding up "cancel each other out" in some sense, maybe the total error from the two procedures wouldn't be that far off. Let's investigate.

The rounding error when rounding any number to zero decimal places can be modelled by a $Unif(-0.5,0.5)$ random variable. We can argue this heuristically, or we can simulate and verify empirically:
```{r roundoff-1}
# Generate a bunch of numbers, it doesn't matter from what distribution
x <- rnorm(10000)
# Round them
y <- round(x)
# Compute the roundoff error
u <- x - y
# Histogram
data_frame(x = u) %>%
  ggplot(aes(x = x)) +
  theme_classic() +
  geom_histogram(bins = 100,fill = "orange",colour = "black") +
  labs(title = "Simulated Round-off Error",
       subtitle = "10,000 Normal Deviates rounded to 0 decimals",
       x = "Round-off Error",
       y = "Count")

```
The approximation seems reasonable. We can test this further using a Quantile-Quantile plot: a plot of the *sample* quantiles against the *theoretical* quantiles of the distribution of interest, i.e. a $Unif(-0.5,0.5)$:
```{r roundoff-2}
data_frame(x = u) %>%
  arrange(x) %>%
  mutate(q = qunif(1:length(u) / (1 + length(u)),min = -0.5,max = 0.5)) %>%
  ggplot(aes(x = q,y = x)) +
  theme_light() +
  geom_point(colour = "darkgrey",size = 0.7) +
  geom_abline(slope = 1,intercept = 0,colour = "red") +
  labs(title = "Uniform QQ-Plot for Round-off Error",
       subtitle = "Testing goodness of fit of a uniform distribution to simulated round-off error",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles")

```
This indicates nearly perfect fit.

We proceed assuming that roundoff error is uniformly distributed on $(-0.5,0.5)$. Letting $y_{i}$ denote the rounded $x_{i}$, we have
\[
x_{i} = y_{i} + u_{i}
\]
where $u_{i} \sim Unif(-0.5,0.5)$ is the roundoff error 
